---
title: "B705 - Week 5 Lecture Notes"
date: "February 6, 2024"
author: "Austin Allen"
format:
  html:
    self-contained: true
    page-layout: full
    title-block-banner: true
    toc: true
    toc-depth: 3
    toc-location: body
    number-sections: false
    html-math-method: katex
    code-fold: true
    code-summary: "Show the code"
    code-overflow: wrap
    code-copy: hover
    code-tools:
        source: false
        toggle: true
        caption: See code
execute: 
  warning: false
    
---



::: {.panel-tabset}

### Tuesday


**Review: Hat matrix, MSE, degrees of freedom**


* $S^2Y.X= MSE = \hat{\sigma^2_{\epsilon}} = \frac{SSE}{n - (p + 1)}$
* Generally, we have to reduce the dimension of the model to focus on the important predictors
* If A is idempotent, $I - A$ is also idempotent. The rank is equal to $trace(A)$ 
* If we have n observations in our sample, and n = p + 1 (nunmber of parameters in model), it is impossible to calculate the MSE because we have 0 degrees of freedom in the error terms


**SSR**

* For a sequential SSR, $SSR(X_1, X_2, X_3) = SSR(X_1) + SSR(X_2 | X_1) + SSR(X_3 | X_1, X_2)$. The disadvantage is not additive
* For the other version of SSR that's like sequential (can't remember teh name of them right now), we're just interested in the contribution of each variable. Thus, we 


